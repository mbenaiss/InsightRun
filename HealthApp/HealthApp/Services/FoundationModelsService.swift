//
//  FoundationModelsService.swift
//  HealthApp
//
//  Service for running on-device LLM inference using Apple's FoundationModels framework
//

import Foundation
import Combine
import FoundationModels

@available(iOS 26.0, *)
@MainActor
class FoundationModelsService: ObservableObject {
    static let shared = FoundationModelsService()

    @Published var isLoading = false
    @Published var isStreaming = false
    @Published var streamedResponse = ""
    @Published var error: String?
    @Published var availability: SystemLanguageModel.Availability?

    private let model = SystemLanguageModel.default
    private var currentSession: LanguageModelSession?
    private var currentTask: Task<Void, Never>?

    private init() {
        // Check model availability on initialization
        Task {
            await checkAvailability()
        }
    }

    // MARK: - Model Availability

    func checkAvailability() async {
        availability = model.availability

        switch model.availability {
        case .available:
            print("âœ… FoundationModels: Model available")

            // Check locale support
            let currentLocale = Locale.current
            let isLocaleSupported = model.supportsLocale(currentLocale)
            print("ğŸŒ FoundationModels: Current locale: \(currentLocale.identifier)")
            print("ğŸŒ FoundationModels: Locale supported: \(isLocaleSupported)")

            if !isLocaleSupported {
                print("âš ï¸ FoundationModels: Current locale not supported")
                error = "La langue actuelle (\(currentLocale.identifier)) n'est pas encore supportÃ©e par Apple Intelligence"
            }

            // Log supported languages
            let supportedLanguages = model.supportedLanguages
            let languageList = supportedLanguages.map { $0.languageCode?.identifier ?? $0.minimalIdentifier }.joined(separator: ", ")
            print("ğŸ“ FoundationModels: Supported languages: \(languageList)")

        case .unavailable(.deviceNotEligible):
            print("âŒ FoundationModels: Device not eligible for Apple Intelligence")
            error = "This device doesn't support Apple Intelligence"
        case .unavailable(.appleIntelligenceNotEnabled):
            print("âš ï¸ FoundationModels: Apple Intelligence not enabled")
            error = "Please enable Apple Intelligence in Settings"
        case .unavailable(.modelNotReady):
            print("â³ FoundationModels: Model downloading or not ready")
            error = "Model is downloading, please try again later"
        case .unavailable(let other):
            print("âŒ FoundationModels: Unavailable - \(other)")
            error = "Model unavailable: \(other)"
        }
    }

    var isAvailable: Bool {
        if case .available = model.availability {
            return true
        }
        return false
    }

    // MARK: - Session Management

    private func createSession(systemPrompt: String) {
        let instructions = systemPrompt.isEmpty
            ? "You are a helpful AI assistant for a health and fitness app."
            : systemPrompt

        currentSession = LanguageModelSession(instructions: instructions)
        print("ğŸ“ FoundationModels: Created new session with instructions")
    }

    // MARK: - Inference

    func generate(prompt: String, systemPrompt: String) async throws -> AsyncStream<String> {
        // Validate prompt
        let trimmedPrompt = prompt.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmedPrompt.isEmpty else {
            print("âŒ FoundationModels: Empty prompt")
            throw FoundationModelsError.inferenceError("Le prompt ne peut pas Ãªtre vide")
        }

        guard trimmedPrompt.count >= 3 else {
            print("âŒ FoundationModels: Prompt too short (\(trimmedPrompt.count) chars)")
            throw FoundationModelsError.inferenceError("Le prompt doit contenir au moins 3 caractÃ¨res")
        }

        // Check availability first
        guard isAvailable else {
            print("âŒ FoundationModels: Model not available")
            throw FoundationModelsError.modelNotAvailable
        }

        // Check locale support
        let currentLocale = Locale.current
        guard model.supportsLocale(currentLocale) else {
            print("âŒ FoundationModels: Locale \(currentLocale.identifier) not supported")
            throw FoundationModelsError.inferenceError("La langue \(currentLocale.identifier) n'est pas encore supportÃ©e")
        }

        // Create new session for each request
        createSession(systemPrompt: systemPrompt)

        guard let session = currentSession else {
            print("âŒ FoundationModels: Session not created")
            throw FoundationModelsError.sessionNotCreated
        }

        isLoading = true
        isStreaming = true
        streamedResponse = ""
        error = nil

        print("ğŸš€ FoundationModels: Starting inference...")
        print("ğŸ“ FoundationModels: Prompt length: \(trimmedPrompt.count) chars")

        return AsyncStream { continuation in
            currentTask = Task {
                do {
                    // Get response from the model
                    print("âš™ï¸ FoundationModels: Calling respond(to:)...")
                    let response = try await session.respond(to: trimmedPrompt)
                    let responseText = response.content

                    await MainActor.run {
                        self.isLoading = false
                    }

                    print("âœ… FoundationModels: Got response (\(responseText.count) chars)")

                    if responseText.isEmpty {
                        print("âš ï¸ FoundationModels: WARNING - Empty response!")
                        error = "The model returned an empty response"
                        isStreaming = false
                        currentTask = nil
                        continuation.finish()
                        return
                    }

                    print("ğŸ“ FoundationModels: Response preview: \(responseText.prefix(200))...")

                    // Check if cancelled before streaming
                    guard !Task.isCancelled else {
                        isStreaming = false
                        currentTask = nil
                        continuation.finish()
                        return
                    }

                    // Stream character by character for progressive response
                    for char in responseText {
                        guard !Task.isCancelled else {
                            isStreaming = false
                            currentTask = nil
                            continuation.finish()
                            return
                        }

                        let charString = String(char)
                        continuation.yield(charString)
                        streamedResponse += charString

                        // Small delay to simulate streaming
                        try? await Task.sleep(nanoseconds: 10_000_000)
                    }

                    isStreaming = false
                    currentTask = nil
                    continuation.finish()
                    print("ğŸ‰ FoundationModels: Streaming completed")

                } catch let error as LanguageModelSession.GenerationError {
                    print("âŒ FoundationModels: GenerationError - \(error)")

                    let errorMessage = self.handleGenerationError(error)

                    await MainActor.run {
                        self.error = errorMessage
                        self.isLoading = false
                        self.isStreaming = false
                        self.currentTask = nil
                    }
                    continuation.finish()

                } catch {
                    print("âŒ FoundationModels: Unexpected error - \(error)")

                    await MainActor.run {
                        self.error = "Erreur inattendue: \(error.localizedDescription)"
                        self.isLoading = false
                        self.isStreaming = false
                        self.currentTask = nil
                    }
                    continuation.finish()
                }
            }
        }
    }

    func stopGeneration() {
        currentTask?.cancel()
        currentTask = nil
        isStreaming = false
    }

    // MARK: - Helper Methods

    func getModelInfo() -> String? {
        guard isAvailable else { return nil }

        return """
        Model: Apple Foundation Model
        Type: On-device (Apple Intelligence)
        Status: Available
        """
    }

    func clearSession() {
        currentSession = nil
        streamedResponse = ""
    }

    // MARK: - Error Handling

    private func handleGenerationError(_ error: LanguageModelSession.GenerationError) -> String {
        switch error {
        case .assetsUnavailable:
            print("ğŸ”´ FoundationModels: Assets unavailable - Model assets may be deleted or downloading")
            return "â³ Le modÃ¨le Apple Intelligence n'est pas disponible. VÃ©rifiez qu'Apple Intelligence est activÃ© et que les modÃ¨les sont tÃ©lÃ©chargÃ©s."

        case .guardrailViolation:
            print("ğŸ›¡ï¸ FoundationModels: Guardrail violation - Content blocked by safety guardrails")
            return "ğŸ›¡ï¸ Votre demande contient du contenu qui ne peut pas Ãªtre traitÃ© pour des raisons de sÃ©curitÃ©. Veuillez reformuler votre question."

        case .refusal(let refusal, _):
            print("ğŸš« FoundationModels: Refusal - Model refused the request")
            // The refusal object may contain more details
            return "ğŸš« Le modÃ¨le ne peut pas rÃ©pondre Ã  cette demande. Veuillez essayer une autre question."

        case .exceededContextWindowSize:
            print("ğŸ“ FoundationModels: Context window exceeded - Too much data in session")
            return "ğŸ“ Trop de donnÃ©es dans la conversation. Veuillez dÃ©marrer une nouvelle session."

        case .rateLimited:
            print("â±ï¸ FoundationModels: Rate limited - Too many requests")
            return "â±ï¸ Trop de requÃªtes. Veuillez patienter quelques instants avant de rÃ©essayer."

        case .concurrentRequests:
            print("ğŸ”„ FoundationModels: Concurrent requests - Multiple requests at once")
            return "ğŸ”„ Une requÃªte est dÃ©jÃ  en cours. Veuillez attendre qu'elle se termine."

        case .decodingFailure:
            print("ğŸ”§ FoundationModels: Decoding failure - Failed to decode response")
            return "ğŸ”§ Erreur de dÃ©codage de la rÃ©ponse. Veuillez rÃ©essayer."

        case .unsupportedLanguageOrLocale:
            print("ğŸŒ FoundationModels: Unsupported language/locale")
            return "ğŸŒ La langue ou locale n'est pas supportÃ©e par le modÃ¨le."

        @unknown default:
            print("â“ FoundationModels: Unknown error - \(error)")
            return "â“ Erreur inconnue: \(error.localizedDescription)"
        }
    }
}

// MARK: - Errors

enum FoundationModelsError: LocalizedError {
    case modelNotAvailable
    case sessionNotCreated
    case inferenceError(String)

    var errorDescription: String? {
        switch self {
        case .modelNotAvailable:
            return "Apple Foundation Model is not available on this device"
        case .sessionNotCreated:
            return "Failed to create language model session"
        case .inferenceError(let message):
            return "Inference error: \(message)"
        }
    }
}
