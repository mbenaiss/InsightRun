//
//  WorkoutAnalysisViewModel.swift
//  HealthApp
//
//  ViewModel for managing AI workout analysis with local SwiftData persistence
//

import Foundation
import SwiftData
import Combine

@MainActor
class WorkoutAnalysisViewModel: ObservableObject {
    @Published var analysisText: String?
    @Published var isLoading = false
    @Published var error: String?
    @Published var analyzedAt: Date?

    private let workout: WorkoutModel
    private var metrics: WorkoutMetrics?
    private let modelContext: ModelContext
    private let aiService: WorkoutAIService
    private var cancellables = Set<AnyCancellable>()

    init(workout: WorkoutModel, metrics: WorkoutMetrics?, modelContext: ModelContext) {
        self.workout = workout
        self.metrics = metrics
        self.modelContext = modelContext
        self.aiService = WorkoutAIService()

        // Observe streaming response in real-time
        aiService.$streamedResponse
            .receive(on: DispatchQueue.main)
            .sink { [weak self] response in
                if !response.isEmpty && response != "üåê Connexion au serveur..." {
                    self?.analysisText = response
                }
            }
            .store(in: &cancellables)

        // Observe errors
        aiService.$error
            .receive(on: DispatchQueue.main)
            .sink { [weak self] errorMsg in
                self?.error = errorMsg
            }
            .store(in: &cancellables)
    }

    // MARK: - Update Metrics

    /// Update metrics before generating analysis
    func updateMetrics(_ newMetrics: WorkoutMetrics?) {
        self.metrics = newMetrics
    }

    // MARK: - Load Analysis

    /// Load analysis from SwiftData cache or generate new one
    func loadAnalysis() async {
        print("üîµ WorkoutAnalysisViewModel: loadAnalysis() called")

        // First, try to load from local cache
        if let cached = fetchCachedAnalysis() {
            print("‚úÖ WorkoutAnalysisViewModel: Found cached analysis")
            print("   - Text length: \(cached.analysisText.count) chars")
            print("   - First 100 chars: \(String(cached.analysisText.prefix(100)))")

            // Validate that the cached analysis is not empty
            if !cached.analysisText.isEmpty && cached.analysisText != "üåê Connexion au serveur..." {
                analysisText = cached.analysisText
                analyzedAt = cached.analyzedAt
                print("‚úÖ WorkoutAnalysisViewModel: Loaded valid cached analysis")
                return
            } else {
                print("‚ö†Ô∏è WorkoutAnalysisViewModel: Cached analysis is invalid, deleting and regenerating")
                // Delete invalid cache
                modelContext.delete(cached)
                try? modelContext.save()
            }
        }

        print("‚ö†Ô∏è WorkoutAnalysisViewModel: No valid cache, generating new analysis")
        // No cache, generate new analysis
        await generateAnalysis()
    }

    // MARK: - Generate Analysis

    /// Generate new AI analysis and save to SwiftData
    func generateAnalysis() async {
        print("üîµ WorkoutAnalysisViewModel: generateAnalysis() started")
        isLoading = true
        error = nil
        analysisText = nil

        print("üîµ WorkoutAnalysisViewModel: isLoading set to true")

        // Build context for AI
        let context = aiService.generateSingleWorkoutContext(workout: workout, metrics: metrics)
        print("üîµ WorkoutAnalysisViewModel: Context built (\(context.count) chars)")

        // Ask AI to analyze this specific workout with a concise, structured response
        let question = """
        Analyse ce workout en profondeur et fournis une r√©ponse CONCISE (max 250 mots) en markdown avec cette structure exacte:

        ## üéØ Points Cl√©s
        - [2-3 insights sur la performance globale]

        ## ‚úÖ M√©triques Optimales
        - [Liste UNIQUEMENT les m√©triques qui sont dans les normes optimales, group√©es en UNE ligne]
        - Exemple: "Cadence (178 spm), Asym√©trie (2.5%), Vitesse marche (5.2 km/h) ‚úÖ"
        - Si AUCUNE m√©trique n'est optimale, omets cette section

        ## ‚ö†Ô∏è √Ä Optimiser
        - [Liste UNIQUEMENT les m√©triques probl√©matiques avec leurs valeurs et cibles]
        - Format: "M√©trique actuelle ‚Üí Cible optimale + Impact/Conseil"
        - Exemple: "Temps contact sol: 285 ms ‚Üí 200-250 ms (perte efficacit√© ~8%)"
        - Si TOUT est optimal, omets cette section et mentionne-le dans Points Cl√©s

        ## üí° Actions Concr√®tes
        - [1-2 exercices sp√©cifiques SEULEMENT s'il y a des m√©triques √† am√©liorer]
        - Sinon omets cette section

        ## üîÑ R√©cup√©ration
        - [1 conseil personnalis√© bas√© sur l'intensit√© et la dur√©e du workout]
        - Mentionne le temps de repos recommand√© avant le prochain entra√Ænement intense
        - Exemple: "48h de repos recommand√©. Privil√©gie sommeil 8h+ et hydratation."

        R√àGLES STRICTES:
        - N'analyse QUE les m√©triques DISPONIBLES dans les donn√©es (ne mentionne JAMAIS "donn√©es non disponibles")
        - Groupe les m√©triques optimales, d√©taille seulement celles √† am√©liorer
        - Sois concis: 1 ligne par m√©trique probl√©matique max
        - Si tout est optimal, dis-le clairement et f√©licite l'athl√®te
        - Section R√©cup√©ration TOUJOURS pr√©sente avec conseil adapt√© √† l'effort
        """

        // Use Grok-4-fast for automatic analysis (always use Grok to keep costs low)
        await aiService.askQuestion(
            about: context,
            question: question,
            mode: .singleWorkout(workout, metrics),
            model: .grok4
        )

        // Wait for streaming to complete by observing isStreaming
        var attempts = 0
        let maxAttempts = 60 // 30 seconds max

        while aiService.isStreaming && attempts < maxAttempts {
            try? await Task.sleep(nanoseconds: 500_000_000) // 0.5s
            attempts += 1
        }

        isLoading = false

        // Check if we got a response (analysisText is already set by Combine observer)
        guard let finalAnalysis = analysisText, !finalAnalysis.isEmpty, aiService.error == nil else {
            error = aiService.error ?? "Erreur lors de l'analyse"
            print("‚ùå WorkoutAnalysisViewModel: No response received")
            return
        }

        print("‚úÖ WorkoutAnalysisViewModel: Streaming complete, saving to SwiftData (\(finalAnalysis.count) chars)")

        // Save to SwiftData
        let analysis = WorkoutAnalysis(
            workoutId: workout.id,
            analysisText: finalAnalysis,
            analyzedAt: Date(),
            model: "grok-4-fast"
        )

        modelContext.insert(analysis)

        do {
            try modelContext.save()
            analyzedAt = analysis.analyzedAt
            print("‚úÖ WorkoutAnalysisViewModel: Saved to SwiftData")

        } catch {
            self.error = "Erreur lors de la sauvegarde: \(error.localizedDescription)"
            print("‚ùå WorkoutAnalysisViewModel: Save failed: \(error)")
        }
    }

    // MARK: - Cache Management

    /// Fetch cached analysis from SwiftData
    private func fetchCachedAnalysis() -> WorkoutAnalysis? {
        let workoutId = workout.id
        let descriptor = FetchDescriptor<WorkoutAnalysis>(
            predicate: #Predicate<WorkoutAnalysis> { analysis in
                analysis.workoutId == workoutId
            }
        )

        do {
            let results = try modelContext.fetch(descriptor)
            return results.first
        } catch {
            print("‚ö†Ô∏è WorkoutAnalysisViewModel: Failed to fetch cached analysis: \(error)")
            return nil
        }
    }

    /// Delete cached analysis and regenerate
    func regenerateAnalysis() async {
        // Delete existing cache
        if let cached = fetchCachedAnalysis() {
            modelContext.delete(cached)
            try? modelContext.save()
        }

        // Generate new
        await generateAnalysis()
    }
}
